{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurações inicias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão do PyTorch: 2.5.1+cu124\n",
      "Versão do Torchvision: 0.20.1+cu124\n",
      "CUDA disponível: True\n",
      "Placa de vídeo: NVIDIA GeForce GTX 1660 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(\"Versão do PyTorch:\", torch.__version__)\n",
    "print(\"Versão do Torchvision:\", torchvision.__version__)\n",
    "print(\"CUDA disponível:\", torch.cuda.is_available())\n",
    "print(\"Placa de vídeo:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Nenhuma\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treinamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "\n",
    "def treinar_modelo():\n",
    "    device = torch.device(0)\n",
    "\n",
    "    # Carrega o modelo\n",
    "    model = YOLO(r\"C:\\projetosML\\auto_Plate_Detection\\outputs\\modelos_treinados\\modelo_first_640_8_2.pt\")  # Primeiro dataset treinado\n",
    "    model.to(device)\n",
    "\n",
    "    print(\"Iniciando o treinamento...\")\n",
    "\n",
    "    # Treinamento do modelo\n",
    "   \n",
    "    model.train(\n",
    "        data='C:\\projetosML/auto_Plate_Detection\\data\\primeiro_dataset\\data.yaml',\n",
    "        epochs=60,\n",
    "        batch=8,\n",
    "        imgsz=544,\n",
    "        optimizer=\"AdamW\",\n",
    "        pretrained=True,\n",
    "        amp=False,\n",
    "        augment=True,  # Ativa augmentations padrão\n",
    "        hsv_h=0.015,  # Variação de matiz\n",
    "        hsv_s=0.7,    # Variação de saturação\n",
    "        hsv_v=0.4,    # Variação de brilho\n",
    "        #scale=0.5,    # Escala para simular objetos distantes\n",
    "        #translate=0.1,  # Translação\n",
    "        #mosaic=1.0,   # Combina imagens\n",
    "        #mixup=0.2     # Mescla imagens\n",
    "    )\n",
    "    # Salva o modelo treinado\n",
    "    model.save(r\"C:\\projetosML\\auto_Plate_Detection\\outputs\\modelos_treinados/new_modelo_br_20epochs.pt\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    treinar_modelo()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLO11n model\n",
    "model = YOLO(\"C:\\projetosML/auto_Plate_Detection\\outputs\\modelos_treinados\\modelo_br_dataArgumetetion_40epochs.pt\")\n",
    "\n",
    "# Define path to video file\n",
    "source = \"C:\\projetosML/auto_Plate_Detection\\inputs/brasil1080p.mp4\"\n",
    "\n",
    "# Run inference on the source\n",
    "#results = model(source, stream=True)  # generator of Results objects\n",
    "\n",
    "model.predict(source=source, show=True, conf=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importando pacotes de outro diretorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Como estamos em 'notebooks', precisamos subir um nível para acessar 'src'\n",
    "projeto_path = os.path.dirname(os.getcwd())  # Sobe um nível\n",
    "sys.path.append(projeto_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Testando o modelo com um video, sem OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from time import time\n",
    "\n",
    "def process_video(model_path, video_path, confiance=0.5):\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    print(f\"Resolução de video: {frame_width}x{frame_height}\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        start_time = time()\n",
    "\n",
    "        #Lendo o frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Fim do vídeo\")\n",
    "            break\n",
    "\n",
    "        #Fazendo a predição\n",
    "        results = model.predict(frame, conf=confiance, batch=64, device=\"gpu\")\n",
    "\n",
    "        #Processando os resultados\n",
    "        detections = results[0].boxes.xyxy.cpu().numpy()  # Coordenadas das caixas\n",
    "        confs = results[0].boxes.conf.cpu().numpy()      # Confianças\n",
    "        classes = results[0].boxes.cls.cpu().numpy()     # Classes\n",
    "\n",
    "\n",
    "\n",
    "        for i, box in enumerate(detections):\n",
    "            x1, y1, x2, y2 = box\n",
    "            conf = confs[i]\n",
    "            cls = classes[i]\n",
    "            \n",
    "            \n",
    "\n",
    "            if conf > confiance:\n",
    "                box = np.array([x1, y1, x2, y2]).astype(int)\n",
    "\n",
    "                # Desenha a caixa delimitadora\n",
    "                cv2.rectangle(frame,\n",
    "                              (box[0], box[1]),\n",
    "                              (box[2], box[3]),\n",
    "                              (0, 255, 0),\n",
    "                              2)\n",
    "                \n",
    "                # Escreve o texto\n",
    "                label = f\"{model.names[int(cls)]} ({conf:.2f})\"\n",
    "                cv2.putText(frame,\n",
    "                            label,\n",
    "                            (box[0], box[1] - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5,\n",
    "                            (0, 255, 0),\n",
    "                            2)\n",
    "                \n",
    "        # Exibindo o frame\n",
    "        fps = 1.0 / (time() - start_time)\n",
    "        cv2.putText(frame,\n",
    "                    f\"FPS: {fps:.2f}\",\n",
    "                    (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1,\n",
    "                    (0, 255, 0),\n",
    "                    2)\n",
    "        \n",
    "        #Mostrando os resultados na tela\n",
    "        cv2.imshow(\"Yolo Detections\", frame)\n",
    "\n",
    "        #Sair do loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_path = r\"C:\\projetosML\\auto_Plate_Detection\\outputs\\modelos_treinados\\new_modelo_br_20epochs.pt\"\n",
    "    video_path = r\"C:\\projetosML\\auto_Plate_Detection\\inputs\\rife4x.mp4\"\n",
    "    process_video(model_path, video_path, confiance=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando o modelo com um video, **com OCR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from time import time\n",
    "from src import paddleOCRdetect\n",
    "\n",
    "\n",
    "def process_video(model_path, video_path, confiance=0.5):\n",
    "    model = YOLO(model_path)\n",
    "    \n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    print(f\"Resolução de video: {frame_width}x{frame_height}\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "    idx = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        start_time = time()\n",
    "\n",
    "        #Lendo o frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"Fim do vídeo\")\n",
    "            break\n",
    "\n",
    "        #Fazendo a predição\n",
    "        results = model.predict(frame, conf=confiance, device=\"gpu\")\n",
    "\n",
    "        #Processando os resultados\n",
    "        detections = results[0].boxes.xyxy.cpu().tolist()  # Coordenadas das caixas\n",
    "        confs = results[0].boxes.conf.cpu().tolist()      # Confianças\n",
    "        classes = results[0].boxes.cls.cpu().tolist()     # Classes\n",
    "\n",
    "\n",
    "\n",
    "        for i, box in enumerate(detections):\n",
    "            x1, y1, x2, y2 = box\n",
    "            \n",
    "\n",
    "\n",
    "            conf = confs[i]\n",
    "            cls = classes[i]\n",
    "            \n",
    "            \n",
    "\n",
    "            if conf > confiance:\n",
    "                box = np.array([x1, y1, x2, y2]).astype(int)\n",
    "                crop_obj = frame[int(box[1]) : int(box[3]), int(box[0]) : int(box[2])]\n",
    "            \n",
    "                #upscale no crop_obj\n",
    "                h, w = crop_obj.shape[:2]\n",
    "                crop_obj = cv2.resize(crop_obj, (w*4, h*4), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "                \n",
    "                plate = paddleOCRdetect.detect_text(crop_obj)\n",
    "                plate = str(plate)\n",
    "                if plate != None:\n",
    "                    print(plate)\n",
    "                    cv2.putText(frame,\n",
    "                            plate,\n",
    "                            (box[0], box[1] - 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5,\n",
    "                            (0, 255, 0),\n",
    "                            2)\n",
    "                \n",
    "                if plate != None:\n",
    "                    text = plate.upper().replace(' ', '').replace('[', '').replace(']', '').replace(\"'\", '')\n",
    "                    \n",
    "                    print(f'Placa detectada: {text}')\n",
    "                    # Padrão antigo: ABC1234\n",
    "                    padrao_antigo = len(text) == 7 and text[:3].isalpha() and text[3:].isdigit()\n",
    "                    \n",
    "                    # Padrão novo: ABC1D23\n",
    "                    padrao_mercosul = (len(text) == 7 and \n",
    "                          text[:3].isalpha() and \n",
    "                          text[3].isdigit() and \n",
    "                          text[4].isalpha() and \n",
    "                          text[5:].isdigit())\n",
    "                    \n",
    "                    if padrao_antigo or padrao_mercosul:\n",
    "                        print(f\"Placa válida: {text}\")\n",
    "                        idx += 1\n",
    "                        cv2.imwrite(f\"C:/projetosML/auto_Plate_Detection/outputs/tests/placa_{idx}.jpg\", crop_obj)\n",
    "                \n",
    "                # Desenha a caixa delimitadora\n",
    "                cv2.rectangle(frame,\n",
    "                              (box[0], box[1]),\n",
    "                              (box[2], box[3]),\n",
    "                              (0, 255, 0),\n",
    "                              2)\n",
    "                \n",
    "                # Escreve o texto\n",
    "                label = f\"{model.names[int(cls)]} ({conf:.2f})\"\n",
    "                cv2.putText(frame,\n",
    "                            label,\n",
    "                            (box[0], box[1] - 10),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5,\n",
    "                            (0, 255, 0),\n",
    "                            2)\n",
    "                \n",
    "        # Exibindo o frame\n",
    "        fps = 1.0 / (time() - start_time)\n",
    "        cv2.putText(frame,\n",
    "                    f\"FPS: {fps:.2f}\",\n",
    "                    (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1,\n",
    "                    (0, 255, 0),\n",
    "                    2)\n",
    "        \n",
    "        #Mostrando os resultados na tela\n",
    "        cv2.imshow(\"Yolo Detections\", frame)\n",
    "\n",
    "        #Sair do loop\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_path = \"C:\\projetosML/auto_Plate_Detection\\outputs\\modelos_treinados\\modelo_br_dataArgumetetion_40epochs.pt\"\n",
    "    video_path = r\"C:\\projetosML\\auto_Plate_Detection\\inputs\\202501291141.mp4\"\n",
    "    process_video(model_path, video_path, confiance=0.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from time import time\n",
    "from src import paddleOCRdetect\n",
    "\n",
    "def process_video(model_path, video_path, output_path, confiance=0.5):\n",
    "    model = YOLO(model_path)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    print(f\"Video resolution: {frame_width}x{frame_height}\")\n",
    "    print(f\"FPS: {fps}\")\n",
    "\n",
    "    # Define the codec and create VideoWriter object\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        start_time = time()\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            print(\"End of video\")\n",
    "            break\n",
    "\n",
    "        results = model.predict(frame, conf=confiance, device=\"gpu\")\n",
    "\n",
    "        detections = results[0].boxes.xyxy.cpu().tolist()\n",
    "        confs = results[0].boxes.conf.cpu().tolist()\n",
    "        classes = results[0].boxes.cls.cpu().tolist()\n",
    "\n",
    "        for i, box in enumerate(detections):\n",
    "            x1, y1, x2, y2 = box\n",
    "            conf = confs[i]\n",
    "            cls = classes[i]\n",
    "\n",
    "            if conf > confiance:\n",
    "                box = np.array([x1, y1, x2, y2]).astype(int)\n",
    "                crop_obj = frame[int(box[1]):int(box[3]), int(box[0]):int(box[2])]\n",
    "            \n",
    "                # Upscale the cropped object\n",
    "                h, w = crop_obj.shape[:2]\n",
    "                crop_obj = cv2.resize(crop_obj, (w*4, h*4), interpolation=cv2.INTER_LANCZOS4)\n",
    "\n",
    "                # Perform OCR\n",
    "                plate = paddleOCRdetect.detect_text(crop_obj)\n",
    "                if plate:\n",
    "                    # Draw the text on frame\n",
    "                    cv2.putText(frame,\n",
    "                            str(plate),\n",
    "                            (box[0], box[1] - 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5,\n",
    "                            (0, 255, 0),\n",
    "                            2)\n",
    "                    print(f'Detected text: {plate}')\n",
    "\n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(frame,\n",
    "                            (box[0], box[1]),\n",
    "                            (box[2], box[3]),\n",
    "                            (0, 255, 0),\n",
    "                            2)\n",
    "                \n",
    "                # Write detection label\n",
    "                label = f\"{model.names[int(cls)]} ({conf:.2f})\"\n",
    "                cv2.putText(frame,\n",
    "                        label,\n",
    "                        (box[0], box[1] - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        0.5,\n",
    "                        (0, 255, 0),\n",
    "                        2)\n",
    "\n",
    "        # Add FPS counter to frame\n",
    "        fps = 1.0 / (time() - start_time)\n",
    "        cv2.putText(frame,\n",
    "                    f\"FPS: {fps:.2f}\",\n",
    "                    (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                    1,\n",
    "                    (0, 255, 0),\n",
    "                    2)\n",
    "        \n",
    "        # Write the frame to output video\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_path = \"C:/projetosML/auto_Plate_Detection/outputs/modelos_treinados/modelo_br_dataArgumetetion_40epochs.pt\"\n",
    "    video_path = r\"C:\\projetosML\\auto_Plate_Detection\\inputs\\simu_ue5_2x.mp4\"\n",
    "    output_path = \"C:/projetosML/auto_Plate_Detection/outputs/processed_video_ue5_2x.mp4\"\n",
    "    process_video(model_path, video_path, output_path, confiance=0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

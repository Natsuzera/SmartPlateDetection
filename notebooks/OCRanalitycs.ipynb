{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Versão do PyTorch: 2.5.1+cu124\n",
      "Versão do Torchvision: 0.20.1+cu124\n",
      "CUDA disponível: True\n",
      "Placa de vídeo: NVIDIA GeForce GTX 1660 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print(\"Versão do PyTorch:\", torch.__version__)\n",
    "print(\"Versão do Torchvision:\", torchvision.__version__)\n",
    "print(\"CUDA disponível:\", torch.cuda.is_available())\n",
    "print(\"Placa de vídeo:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Nenhuma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Como estamos em 'notebooks', precisamos subir um nível para acessar 'src'\n",
    "projeto_path = os.path.dirname(os.getcwd())  # Sobe um nível\n",
    "sys.path.append(projeto_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EasyOCR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from time import time\n",
    "from src import OCRdetect  # EasyOCR\n",
    "import csv\n",
    "\n",
    "def process_video(model_path, video_path, confiance=0.5):\n",
    "    model = YOLO(model_path)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    with open('analitycs/easyocr_frame_metrics.csv', 'w', newline='') as frame_csv, \\\n",
    "         open('analitycs/easyocr_detection_metrics.csv', 'w', newline='') as detect_csv:\n",
    "\n",
    "        frame_writer = csv.DictWriter(frame_csv, fieldnames=[\n",
    "            'frame_number', 'yolo_time', 'total_processing_time', 'num_detections'\n",
    "        ])\n",
    "        frame_writer.writeheader()\n",
    "\n",
    "        detect_writer = csv.DictWriter(detect_csv, fieldnames=[\n",
    "            'frame_number', 'detection_index', 'ocr_time', \n",
    "            'plate_detected', 'plate_text', 'confidence', 'class'\n",
    "        ])\n",
    "        detect_writer.writeheader()\n",
    "\n",
    "        frame_counter = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            frame_counter += 1\n",
    "            frame_start_time = time()\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "\n",
    "            # YOLO\n",
    "            yolo_start = time()\n",
    "            results = model.predict(frame, conf=confiance, device=\"gpu\")\n",
    "            yolo_time = time() - yolo_start\n",
    "\n",
    "            detections = results[0].boxes.xyxy.cpu().tolist()\n",
    "            confs = results[0].boxes.conf.cpu().tolist()\n",
    "            classes = results[0].boxes.cls.cpu().tolist()\n",
    "\n",
    "            valid_detections = [\n",
    "                (detections[i], confs[i], classes[i]) \n",
    "                for i in range(len(detections)) if confs[i] > confiance\n",
    "            ]\n",
    "\n",
    "            for detection_idx, (box, conf, cls) in enumerate(valid_detections):\n",
    "                x1, y1, x2, y2 = box\n",
    "                crop_obj = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "                \n",
    "                try:\n",
    "                    h, w = crop_obj.shape[:2]\n",
    "                    crop_obj = cv2.resize(crop_obj, (w*4, h*4), interpolation=cv2.INTER_LANCZOS4)\n",
    "                except: continue\n",
    "\n",
    "                # EasyOCR\n",
    "                ocr_start = time()\n",
    "                plate = OCRdetect.detect_text(crop_obj)\n",
    "                ocr_time = time() - ocr_start\n",
    "\n",
    "                plate_detected = len(plate) > 0\n",
    "                plate_text = '|'.join(plate) if plate_detected else ''\n",
    "\n",
    "                detect_writer.writerow({\n",
    "                    'frame_number': frame_counter,\n",
    "                    'detection_index': detection_idx,\n",
    "                    'ocr_time': ocr_time,\n",
    "                    'plate_detected': plate_detected,\n",
    "                    'plate_text': plate_text,\n",
    "                    'confidence': conf,\n",
    "                    'class': cls\n",
    "                })\n",
    "\n",
    "            frame_writer.writerow({\n",
    "                'frame_number': frame_counter,\n",
    "                'yolo_time': yolo_time,\n",
    "                'total_processing_time': time() - frame_start_time,\n",
    "                'num_detections': len(valid_detections)\n",
    "            })\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_path = \"C:/projetosML/auto_Plate_Detection/outputs/modelos_treinados/modelo_br_dataArgumetetion_40epochs.pt\"\n",
    "    video_path = r\"C:\\projetosML\\auto_Plate_Detection\\inputs\\simulation.mkv\"\n",
    "    process_video(model_path, video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TesseractOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from time import time\n",
    "from src import tesseractOCR  #TesseractOCR\n",
    "import csv\n",
    "\n",
    "def process_video(model_path, video_path, confiance=0.5):\n",
    "    model = YOLO(model_path)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    with open('analitycs/tesseract_frame_metrics.csv', 'w', newline='') as frame_csv, \\\n",
    "         open('analitycs/tesseract_detection_metrics.csv', 'w', newline='') as detect_csv:\n",
    "\n",
    "        frame_writer = csv.DictWriter(frame_csv, fieldnames=[\n",
    "            'frame_number', 'yolo_time', 'total_processing_time', 'num_detections'\n",
    "        ])\n",
    "        frame_writer.writeheader()\n",
    "\n",
    "        detect_writer = csv.DictWriter(detect_csv, fieldnames=[\n",
    "            'frame_number', 'detection_index', 'ocr_time', \n",
    "            'plate_detected', 'plate_text', 'confidence', 'class'\n",
    "        ])\n",
    "        detect_writer.writeheader()\n",
    "\n",
    "        frame_counter = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            frame_counter += 1\n",
    "            frame_start_time = time()\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "\n",
    "            # YOLO\n",
    "            yolo_start = time()\n",
    "            results = model.predict(frame, conf=confiance, device=\"gpu\")\n",
    "            yolo_time = time() - yolo_start\n",
    "\n",
    "            detections = results[0].boxes.xyxy.cpu().tolist()\n",
    "            confs = results[0].boxes.conf.cpu().tolist()\n",
    "            classes = results[0].boxes.cls.cpu().tolist()\n",
    "\n",
    "            valid_detections = [\n",
    "                (detections[i], confs[i], classes[i]) \n",
    "                for i in range(len(detections)) if confs[i] > confiance\n",
    "            ]\n",
    "\n",
    "            for detection_idx, (box, conf, cls) in enumerate(valid_detections):\n",
    "                x1, y1, x2, y2 = box\n",
    "                crop_obj = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "                \n",
    "                try:\n",
    "                    h, w = crop_obj.shape[:2]\n",
    "                    crop_obj = cv2.resize(crop_obj, (w*4, h*4), interpolation=cv2.INTER_LANCZOS4)\n",
    "                except: continue\n",
    "\n",
    "                # TesseractOCR\n",
    "                ocr_start = time()\n",
    "                plate = tesseractOCR.detect_text(crop_obj)\n",
    "                ocr_time = time() - ocr_start\n",
    "\n",
    "                plate_detected = len(plate) > 0 and plate[0] != ''\n",
    "                plate_text = plate[0] if plate_detected else ''  # Pegar primeiro elemento\n",
    "\n",
    "                detect_writer.writerow({\n",
    "                    'frame_number': frame_counter,\n",
    "                    'detection_index': detection_idx,\n",
    "                    'ocr_time': ocr_time,\n",
    "                    'plate_detected': plate_detected,\n",
    "                    'plate_text': plate_text,\n",
    "                    'confidence': conf,\n",
    "                    'class': cls\n",
    "                })\n",
    "\n",
    "            frame_writer.writerow({\n",
    "                'frame_number': frame_counter,\n",
    "                'yolo_time': yolo_time,\n",
    "                'total_processing_time': time() - frame_start_time,\n",
    "                'num_detections': len(valid_detections)\n",
    "            })\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_path = \"C:/projetosML/auto_Plate_Detection/outputs/modelos_treinados/modelo_br_dataArgumetetion_40epochs.pt\"\n",
    "    video_path = r\"C:\\projetosML\\auto_Plate_Detection\\inputs\\202501291141.mp4\"\n",
    "    process_video(model_path, video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PadleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from time import time\n",
    "from src import paddleOCRdetect  # PaddleOCR\n",
    "import csv\n",
    "\n",
    "def process_video(model_path, video_path, confiance=0.5):\n",
    "    model = YOLO(model_path)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    with open('analitycs/paddleocr_frame_metrics.csv', 'w', newline='') as frame_csv, \\\n",
    "         open('analitycs/paddleocr_detection_metrics.csv', 'w', newline='') as detect_csv:\n",
    "\n",
    "        frame_writer = csv.DictWriter(frame_csv, fieldnames=[\n",
    "            'frame_number', 'yolo_time', 'total_processing_time', 'num_detections'\n",
    "        ])\n",
    "        frame_writer.writeheader()\n",
    "\n",
    "        detect_writer = csv.DictWriter(detect_csv, fieldnames=[\n",
    "            'frame_number', 'detection_index', 'ocr_time', \n",
    "            'plate_detected', 'plate_text', 'confidence', 'class'\n",
    "        ])\n",
    "        detect_writer.writeheader()\n",
    "\n",
    "        frame_counter = 0\n",
    "\n",
    "        while cap.isOpened():\n",
    "            frame_counter += 1\n",
    "            frame_start_time = time()\n",
    "\n",
    "            ret, frame = cap.read()\n",
    "            if not ret: break\n",
    "\n",
    "            # YOLO\n",
    "            yolo_start = time()\n",
    "            results = model.predict(frame, conf=confiance, device=\"gpu\")\n",
    "            yolo_time = time() - yolo_start\n",
    "\n",
    "            detections = results[0].boxes.xyxy.cpu().tolist()\n",
    "            confs = results[0].boxes.conf.cpu().tolist()\n",
    "            classes = results[0].boxes.cls.cpu().tolist()\n",
    "\n",
    "            valid_detections = [\n",
    "                (detections[i], confs[i], classes[i]) \n",
    "                for i in range(len(detections)) if confs[i] > confiance\n",
    "            ]\n",
    "\n",
    "            for detection_idx, (box, conf, cls) in enumerate(valid_detections):\n",
    "                x1, y1, x2, y2 = box\n",
    "                crop_obj = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "                \n",
    "                try:\n",
    "                    h, w = crop_obj.shape[:2]\n",
    "                    crop_obj = cv2.resize(crop_obj, (w*4, h*4), interpolation=cv2.INTER_LANCZOS4)\n",
    "                except: continue\n",
    "\n",
    "                # PaddleOCR\n",
    "                ocr_start = time()\n",
    "                plate = paddleOCRdetect.detect_text(crop_obj)\n",
    "                ocr_time = time() - ocr_start\n",
    "\n",
    "                plate_detected = len(plate) > 0\n",
    "                plate_text = '|'.join(plate) if plate_detected else ''\n",
    "\n",
    "                detect_writer.writerow({\n",
    "                    'frame_number': frame_counter,\n",
    "                    'detection_index': detection_idx,\n",
    "                    'ocr_time': ocr_time,\n",
    "                    'plate_detected': plate_detected,\n",
    "                    'plate_text': plate_text,\n",
    "                    'confidence': conf,\n",
    "                    'class': cls\n",
    "                })\n",
    "\n",
    "            frame_writer.writerow({\n",
    "                'frame_number': frame_counter,\n",
    "                'yolo_time': yolo_time,\n",
    "                'total_processing_time': time() - frame_start_time,\n",
    "                'num_detections': len(valid_detections)\n",
    "            })\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    model_path = \"C:/projetosML/auto_Plate_Detection/outputs/modelos_treinados/modelo_br_dataArgumetetion_40epochs.pt\"\n",
    "    video_path = r\"C:\\projetosML\\auto_Plate_Detection\\inputs\\202501291141.mp4\"\n",
    "    process_video(model_path, video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analize dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparação de Desempenho ===\n",
      "| OCR Model   |   Total Valid Plates |   Accuracy (%) |   Avg OCR Time (ms) |   Avg YOLO Time (ms) |   Total Detections |\n",
      "|:------------|---------------------:|---------------:|--------------------:|---------------------:|-------------------:|\n",
      "| easyocr     |                 3521 |        17.0906 |             58.771  |              30.7459 |              20602 |\n",
      "| tesseract   |                 3302 |        16.1475 |            263.429  |              56.7266 |              20449 |\n",
      "| paddleocr   |                11560 |        56.5336 |             49.1595 |              36.4519 |              20448 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def validate_plate(text):\n",
    "    # Limpa o texto, mantendo apenas letras e números, e converte para maiúsculas\n",
    "    text = re.sub(r'[^A-Z0-9]', '', text.upper())\n",
    "    \n",
    "    # Verifica se o texto tem exatamente 6 caracteres após a limpeza\n",
    "    if len(text) != 6:\n",
    "        return False\n",
    "    \n",
    "    # Processa a parte das letras (posições 1 e 2) substituindo '0' por 'O'\n",
    "    letters_part = text[1:3].replace('0', 'O')\n",
    "    # Reconstroi o texto com as letras ajustadas\n",
    "    processed_text = text[0] + letters_part + text[3:]\n",
    "    \n",
    "    # Verifica se o texto processado corresponde ao padrão da placa\n",
    "    padrao_custom = re.match(r'^\\d[A-Z]{2}\\d{3}$', processed_text)\n",
    "    return bool(padrao_custom)\n",
    "\n",
    "def analyze_results(ocr_type):\n",
    "    frame_metrics = pd.read_csv(f'analitycs/{ocr_type}_frame_metrics.csv')\n",
    "    detect_metrics = pd.read_csv(f'analitycs/{ocr_type}_detection_metrics.csv')\n",
    "    \n",
    "    detect_metrics['valid_plate'] = detect_metrics['plate_text'].apply(\n",
    "        lambda x: validate_plate(str(x))\n",
    "    )\n",
    "    \n",
    "    total_valid = detect_metrics['valid_plate'].sum()\n",
    "    avg_ocr_time = detect_metrics['ocr_time'].mean()\n",
    "    avg_yolo_time = frame_metrics['yolo_time'].mean()\n",
    "    \n",
    "    return {\n",
    "        'OCR Model': ocr_type,\n",
    "        'Total Valid Plates': total_valid,\n",
    "        'Accuracy (%)': (total_valid / len(detect_metrics)) * 100 if len(detect_metrics) > 0 else 0,\n",
    "        'Avg OCR Time (ms)': avg_ocr_time * 1000,\n",
    "        'Avg YOLO Time (ms)': avg_yolo_time * 1000,\n",
    "        'Total Detections': len(detect_metrics)\n",
    "    }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    easyocr_stats = analyze_results('easyocr')\n",
    "    tesseract_stats = analyze_results('tesseract')\n",
    "    paddleocr_stats = analyze_results('paddleocr')\n",
    "    \n",
    "    df_comparison = pd.DataFrame([easyocr_stats, tesseract_stats, paddleocr_stats])\n",
    "    print(\"\\n=== Comparação de Desempenho ===\")\n",
    "    print(df_comparison.to_markdown(index=False))\n",
    "    \n",
    "    # Salvar resultados em CSV\n",
    "    df_comparison.to_csv('ocr_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análise visual completa! Verifique a pasta 'analise_visual'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# Verificar estilos disponíveis e configurar\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"pastel\")\n",
    "MODELOS = ['easyocr', 'tesseract', 'paddleocr']\n",
    "\n",
    "def criar_graficos_avancados():\n",
    "    # Criar pasta para os gráficos\n",
    "    os.makedirs('analise_visual', exist_ok=True)\n",
    "    \n",
    "    # Carregar e combinar dados de todos os modelos\n",
    "    dados_completos = []\n",
    "    for modelo in MODELOS:\n",
    "        # Ler dados de detecção\n",
    "        deteccao = pd.read_csv(f'analitycs/{modelo}_detection_metrics.csv')\n",
    "        deteccao['modelo'] = modelo\n",
    "        \n",
    "        # Ler dados de frames\n",
    "        frames = pd.read_csv(f'analitycs/{modelo}_frame_metrics.csv')\n",
    "        frames['modelo'] = modelo\n",
    "        \n",
    "        dados_completos.append(deteccao)\n",
    "        dados_completos.append(frames)\n",
    "    \n",
    "    df_full = pd.concat(dados_completos, ignore_index=True)\n",
    "    \n",
    "    # 1. Gráfico de Desempenho Temporal por Modelo\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    for modelo in MODELOS:\n",
    "        # Dados de frames\n",
    "        frame_data = df_full[(df_full['modelo'] == modelo) & (df_full['frame_number'].notnull())]\n",
    "        plt.plot(frame_data['frame_number'], frame_data['yolo_time'].rolling(10).mean(), \n",
    "                 label=f'{modelo} - YOLO', linestyle='--')\n",
    "        plt.plot(frame_data['frame_number'], frame_data['total_processing_time'].rolling(10).mean(),\n",
    "                 label=f'{modelo} - Total', linewidth=2)\n",
    "    \n",
    "    plt.title('Desempenho Temporal dos Modelos (Média Móvel de 10 frames)')\n",
    "    plt.xlabel('Número do Frame')\n",
    "    plt.ylabel('Tempo de Processamento (s)')\n",
    "    plt.legend()\n",
    "    plt.savefig('analise_visual/desempenho_temporal.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Distribuição de Confiança nas Detecções\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for modelo in MODELOS:\n",
    "        dados_modelo = df_full[(df_full['modelo'] == modelo) & (df_full['confidence'].notnull())]\n",
    "        sns.kdeplot(dados_modelo['confidence'], label=modelo, fill=True, alpha=0.3)\n",
    "    \n",
    "    plt.title('Distribuição de Confiança nas Detecções por Modelo')\n",
    "    plt.xlabel('Confiança da Detecção')\n",
    "    plt.ylabel('Densidade')\n",
    "    plt.legend()\n",
    "    plt.savefig('analise_visual/distribuicao_confianca.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Comparação de Detecções Válidas vs Inválidas\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    validas = []\n",
    "    for modelo in MODELOS:\n",
    "        deteccao = pd.read_csv(f'analitycs/{modelo}_detection_metrics.csv')\n",
    "        validas.append(deteccao['plate_detected'].sum())\n",
    "    \n",
    "    plt.bar(MODELOS, validas, label='Válidas')\n",
    "    plt.bar(MODELOS, [len(pd.read_csv(f'analitycs/{m}_detection_metrics.csv')) - v for m,v in zip(MODELOS, validas)], \n",
    "            bottom=validas, label='Inválidas')\n",
    "    plt.title('Detecções Válidas vs Inválidas por Modelo')\n",
    "    plt.xlabel('Modelo OCR')\n",
    "    plt.ylabel('Quantidade de Detecções')\n",
    "    plt.legend()\n",
    "    plt.savefig('analise_visual/validas_vs_invalidas.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Análise de Desempenho por Frame\n",
    "    fig, axs = plt.subplots(3, 1, figsize=(15, 12))\n",
    "    for idx, modelo in enumerate(MODELOS):\n",
    "        frame_data = pd.read_csv(f'analitycs/{modelo}_frame_metrics.csv')\n",
    "        ax = axs[idx]\n",
    "        \n",
    "        # Gráfico de linhas para tempos de processamento\n",
    "        ax.plot(frame_data['frame_number'], frame_data['yolo_time'], \n",
    "                label='Tempo YOLO', alpha=0.7)\n",
    "        ax.plot(frame_data['frame_number'], frame_data['total_processing_time'], \n",
    "                label='Tempo Total', linewidth=2)\n",
    "        \n",
    "        # Gráfico de barras para número de detecções\n",
    "        ax2 = ax.twinx()\n",
    "        ax2.bar(frame_data['frame_number'], frame_data['num_detections'], \n",
    "                alpha=0.3, color='red', label='Detecções')\n",
    "        \n",
    "        ax.set_title(f'Desempenho do {modelo.capitalize()} por Frame')\n",
    "        ax.set_xlabel('Frame')\n",
    "        ax.set_ylabel('Tempo (s)')\n",
    "        ax2.set_ylabel('Número de Detecções')\n",
    "        ax.legend(loc='upper left')\n",
    "        ax2.legend(loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('analise_visual/desempenho_por_frame.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 5. Heatmap de Detecções por Frame\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    heatmap_data = pd.pivot_table(df_full[df_full['frame_number'].notnull()], \n",
    "                                values='num_detections', \n",
    "                                index='frame_number', \n",
    "                                columns='modelo')\n",
    "    sns.heatmap(heatmap_data.T, cmap='viridis', cbar_kws={'label': 'Número de Detecções'})\n",
    "    plt.title('Frequência de Detecções por Frame e Modelo')\n",
    "    plt.xlabel('Número do Frame')\n",
    "    plt.ylabel('Modelo OCR')\n",
    "    plt.savefig('analise_visual/heatmap_deteccoes.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # 6. Comparação de Tempos de Processamento\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    tempos = []\n",
    "    for modelo in MODELOS:\n",
    "        dados = pd.read_csv(f'analitycs/{modelo}_frame_metrics.csv')\n",
    "        tempos.append({\n",
    "            'modelo': modelo,\n",
    "            'YOLO': dados['yolo_time'].mean(),\n",
    "            'OCR': dados['total_processing_time'].mean() - dados['yolo_time'].mean()\n",
    "        })\n",
    "    \n",
    "    df_tempos = pd.DataFrame(tempos).set_index('modelo')\n",
    "    df_tempos.plot(kind='bar', stacked=True, ax=plt.gca())\n",
    "    plt.title('Distribuição de Tempos de Processamento por Modelo')\n",
    "    plt.ylabel('Tempo Médio (s)')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.savefig('analise_visual/tempos_processamento.png')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    criar_graficos_avancados()\n",
    "    print(\"Análise visual completa! Verifique a pasta 'analise_visual'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danie\\AppData\\Local\\Temp\\ipykernel_17236\\2328361898.py:125: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x='Modelo', y='Taxa Acerto', data=df_geral, palette=CORES.values())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Análise final gerada na pasta 'analise_final'!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"pastel\")\n",
    "MODELOS = ['easyocr', 'tesseract', 'paddleocr']\n",
    "CORES = {'easyocr': '#66c2a5', 'tesseract': '#fc8d62', 'paddleocr': '#8da0cb'}\n",
    "\n",
    "def validate_plate(text):\n",
    "    text = re.sub(r'[^A-Z0-9]', '', text.upper())\n",
    "    if len(text) != 6:\n",
    "        return False\n",
    "    letters_part = text[1:3].replace('0', 'O')\n",
    "    processed_text = text[0] + letters_part + text[3:]\n",
    "    return bool(re.match(r'^\\d[A-Z]{2}\\d{3}$', processed_text))\n",
    "\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return df[(df[column] <= (Q3 + 1.5 * IQR))]\n",
    "\n",
    "def criar_graficos_final():\n",
    "    os.makedirs('analise_final', exist_ok=True)\n",
    "    \n",
    "    # Dados consolidados\n",
    "    dados_gerais = []\n",
    "    dados_validacoes = []\n",
    "    \n",
    "    for modelo in MODELOS:\n",
    "        # Carregar e limpar dados\n",
    "        deteccao = pd.read_csv(f'analitycs/{modelo}_detection_metrics.csv')\n",
    "        frame = pd.read_csv(f'analitycs/{modelo}_frame_metrics.csv')\n",
    "        frame = remove_outliers(frame, 'total_processing_time')\n",
    "        \n",
    "        # Processar validações\n",
    "        deteccao['valid_format'] = deteccao['plate_text'].apply(lambda x: validate_plate(str(x)))\n",
    "        validas_ocr = deteccao['plate_detected'].sum()\n",
    "        validas_formato = deteccao['valid_format'].sum()\n",
    "        \n",
    "        # Salvar dados\n",
    "        dados_gerais.append({\n",
    "            'Modelo': modelo.upper(),\n",
    "            'OCR Validas': validas_ocr,\n",
    "            'Formato Valido': validas_formato,\n",
    "            'Total Detecções': len(deteccao)\n",
    "        })\n",
    "        \n",
    "        # Preparar dados para gráficos de validação\n",
    "        dados_validacoes.append({\n",
    "            'Modelo': modelo.upper(),\n",
    "            'Tipo': 'Validação OCR',\n",
    "            'Quantidade': validas_ocr\n",
    "        })\n",
    "        dados_validacoes.append({\n",
    "            'Modelo': modelo.upper(),\n",
    "            'Tipo': 'Formato Correto',\n",
    "            'Quantidade': validas_formato\n",
    "        })\n",
    "    \n",
    "    df_geral = pd.DataFrame(dados_gerais)\n",
    "    df_validacoes = pd.DataFrame(dados_validacoes)\n",
    "    \n",
    "    # 1. Comparação de Validações\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.barplot(x='Modelo', y='Quantidade', hue='Tipo', data=df_validacoes)\n",
    "    plt.title('Comparação de Detecções Validadas vs Formato Correto')\n",
    "    plt.ylabel('Quantidade')\n",
    "    plt.legend(title='Tipo de Validação')\n",
    "    plt.savefig('analise_final/comparacao_validacoes.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 2. Evolução Temporal Limpa\n",
    "    plt.figure(figsize=(12,6))\n",
    "    for modelo in MODELOS:\n",
    "        frame_data = pd.read_csv(f'analitycs/{modelo}_frame_metrics.csv')\n",
    "        frame_data = remove_outliers(frame_data, 'total_processing_time')\n",
    "        \n",
    "        sns.lineplot(\n",
    "            x='frame_number', \n",
    "            y='total_processing_time', \n",
    "            data=frame_data,\n",
    "            label=modelo.upper(),\n",
    "            color=CORES[modelo],\n",
    "            estimator='median',\n",
    "            errorbar=None,\n",
    "            linewidth=1.5\n",
    "        )\n",
    "    \n",
    "    plt.title('Evolução do Tempo de Processamento (Outliers Removidos)')\n",
    "    plt.xlabel('Número do Frame')\n",
    "    plt.ylabel('Tempo Total (s)')\n",
    "    plt.legend()\n",
    "    plt.savefig('analise_final/evolucao_temporal_limpa.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 3. Gráfico de Confiança Simplificado\n",
    "    plt.figure(figsize=(12,6))\n",
    "    for modelo in MODELOS:\n",
    "        dados = pd.read_csv(f'analitycs/{modelo}_detection_metrics.csv')\n",
    "        dados['Valido'] = dados['plate_detected'].apply(lambda x: 'Válida' if x else 'Inválida')\n",
    "        \n",
    "        sns.boxplot(\n",
    "            x='Modelo', \n",
    "            y='confidence', \n",
    "            hue='Valido',\n",
    "            data=dados.assign(Modelo=modelo.upper()),\n",
    "            palette={'Válida': CORES[modelo], 'Inválida': '#ff0000'},\n",
    "            width=0.4\n",
    "        )\n",
    "    \n",
    "    plt.title('Distribuição de Confiança por Validade (OCR)')\n",
    "    plt.xlabel('Modelo')\n",
    "    plt.ylabel('Confiança')\n",
    "    plt.legend(title='Validação')\n",
    "    plt.savefig('analise_final/boxplot_confianca.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # 4. Taxa de Acerto no Formato\n",
    "    plt.figure(figsize=(10,6))\n",
    "    df_geral['Taxa Acerto'] = (df_geral['Formato Valido'] / df_geral['Total Detecções']) * 100\n",
    "    sns.barplot(x='Modelo', y='Taxa Acerto', data=df_geral, palette=CORES.values())\n",
    "    \n",
    "    for index, row in df_geral.iterrows():\n",
    "        plt.text(index, row['Taxa Acerto'] + 1, f\"{row['Taxa Acerto']:.1f}%\", ha='center')\n",
    "    \n",
    "    plt.title('Taxa de Acerto no Formato da Placa')\n",
    "    plt.ylabel('Taxa de Acerto (%)')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.savefig('analise_final/taxa_acerto_formato.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    criar_graficos_final()\n",
    "    print(\"Análise final gerada na pasta 'analise_final'!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criar_grafico_bottleneck():\n",
    "    os.makedirs('analise_final', exist_ok=True)\n",
    "    \n",
    "    # Dados de processamento\n",
    "    dados_processamento = []\n",
    "    \n",
    "    for modelo in MODELOS:\n",
    "        # Carregar dados limpos\n",
    "        frame_data = pd.read_csv(f'analitycs/{modelo}_frame_metrics.csv')\n",
    "        frame_data = remove_outliers(frame_data, 'yolo_time')\n",
    "        deteccao_data = pd.read_csv(f'analitycs/{modelo}_detection_metrics.csv')\n",
    "        \n",
    "        # Calcular métricas-chave\n",
    "        media_yolo = frame_data['yolo_time'].mean() * 1000  # ms\n",
    "        media_ocr = deteccao_data['ocr_time'].mean() * 1000  # ms por detecção\n",
    "        deteccoes_por_frame = frame_data['num_detections'].mean()\n",
    "        \n",
    "        # Calcular contribuição total\n",
    "        contrib_yolo = media_yolo\n",
    "        contrib_ocr_total = media_ocr * deteccoes_por_frame\n",
    "        \n",
    "        dados_processamento.extend([\n",
    "            {'Modelo': modelo.upper(), 'Componente': 'YOLO', 'Tempo (ms)': contrib_yolo},\n",
    "            {'Modelo': modelo.upper(), 'Componente': 'OCR', 'Tempo (ms)': contrib_ocr_total}\n",
    "        ])\n",
    "    \n",
    "    df_processamento = pd.DataFrame(dados_processamento)\n",
    "    \n",
    "    # Gráfico de Comparação\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    ax = sns.barplot(x='Modelo', y='Tempo (ms)', hue='Componente', data=df_processamento, palette='coolwarm')\n",
    "    \n",
    "    # Anotações personalizadas\n",
    "    for p in ax.patches:\n",
    "        ax.annotate(f\"{p.get_height():.1f} ms\", \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                   ha='center', va='center', \n",
    "                   xytext=(0, 7), \n",
    "                   textcoords='offset points',\n",
    "                   fontsize=9)\n",
    "    \n",
    "    plt.title('Contribuição do YOLO vs OCR no Tempo Total por Frame')\n",
    "    plt.ylabel('Tempo Médio por Frame (ms)')\n",
    "    plt.legend(title='Componente')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.savefig('analise_final/bottleneck_analysis.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Adicionar esta chamada no final da função criar_graficos_final()\n",
    "criar_grafico_bottleneck()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
